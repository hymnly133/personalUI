"""
SimpleGraph - æ ¸å¿ƒçŸ¥è¯†å›¾è°±ç®¡ç†ç³»ç»Ÿ

é¢å‘å¯¹è±¡çš„çŸ¥è¯†å›¾è°±ç®¡ç†ç±»ï¼Œæ”¯æŒï¼š
- å¼‚æ­¥ä»»åŠ¡é˜Ÿåˆ—å¤„ç†
- ä»»åŠ¡éš”ç¦»ï¼ˆå‰¯æœ¬systemï¼‰
- LLMæ™ºèƒ½åˆå¹¶
- ä»»åŠ¡å¹¶å‘æ§åˆ¶
- è¿›åº¦è¿½è¸ªå’Œå›è°ƒ
"""

import asyncio
import copy
import os
import yaml
from pathlib import Path
from typing import Dict, List, Optional, Callable, Any
from datetime import datetime

from src.models.entity import (
    System,
    Entity,
    ClassDefinition,
    PropertyDefinition,
    ClassInstance,
)
from src.models.graph import Graph
from src.models.task import Task, generate_task_id
from src.models.delta import (
    GraphDelta,
    ClassDelta,
    EntityDelta,
    RelationshipDelta,
    PropertyDelta,
)
from src.models.relationship import Relationship
from src.llm.client import LLMClient
from src.updaters.system_updater import SystemUpdater
from src.extractors.extractor import GraphExtractor
from src.combiners.smart_merger import SmartMerger
from src.combiners.combiner import Combiner
from src.search.search_engine import SearchEngine
from src.utils.logger import get_logger

logger = get_logger(__name__)


class SimpleGraph:
    """
    SimpleGraph - çŸ¥è¯†å›¾è°±ç®¡ç†æ ¸å¿ƒç±»

    åŠŸèƒ½ï¼š
    - æäº¤ä»»åŠ¡ï¼ˆsubmit_taskï¼‰
    - å–æ¶ˆä»»åŠ¡ï¼ˆcancel_taskï¼‰
    - æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€ï¼ˆget_task_statusï¼‰
    - ä¿å­˜å’Œå¯è§†åŒ–ï¼ˆsave, visualizeï¼‰
    - ç»Ÿè®¡ä¿¡æ¯ï¼ˆget_statisticsï¼‰
    - è¿›åº¦è¿½è¸ªï¼ˆset_progress_callback, get_task_progressï¼‰

    ä»»åŠ¡å¤„ç†æµç¨‹ï¼ˆä¸¤é˜¶æ®µæ¶æ„ï¼‰ï¼š
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ é˜¶æ®µ1: æå–é˜¶æ®µï¼ˆå¯å¹¶è¡Œï¼‰                                     â”‚
    â”‚ - å¤šä¸ª workers å¹¶è¡Œå¤„ç†ä»»åŠ¡                                  â”‚
    â”‚ - System æ›´æ–°ï¼ˆä½¿ç”¨ä»»åŠ¡å‰¯æœ¬ï¼‰                                â”‚
    â”‚ - å®ä½“å’Œå…³ç³»æå–                                             â”‚
    â”‚ - ç”Ÿæˆ GraphDelta                                           â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“ è¿›å…¥åˆå¹¶é˜Ÿåˆ—
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ é˜¶æ®µ2: åˆå¹¶é˜¶æ®µï¼ˆä¸²è¡Œæ‰§è¡Œï¼‰                                   â”‚
    â”‚ - å•ä¸ª merge worker ä¸²è¡Œå¤„ç†                                 â”‚
    â”‚ - LLM æ™ºèƒ½åˆå¹¶ï¼ˆå»é‡ã€å¯¹é½ã€å†²çªè§£å†³ï¼‰                        â”‚
    â”‚ - åº”ç”¨åˆ°ä¸» system/graph                                      â”‚
    â”‚ - ç¡®ä¿æ•°æ®ä¸€è‡´æ€§å’Œåˆå¹¶è´¨é‡                                   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    ä¼˜åŠ¿ï¼š
    1. æå–é˜¶æ®µå¯ä»¥å……åˆ†å¹¶è¡Œï¼Œæé«˜ååé‡
    2. åˆå¹¶é˜¶æ®µä¸²è¡Œæ‰§è¡Œï¼Œä¿è¯æ•°æ®ä¸€è‡´æ€§
    3. è¯¦ç»†çš„è¿›åº¦é€šçŸ¥ï¼ŒåŒ…æ‹¬ç­‰å¾…åˆå¹¶çŠ¶æ€
    4. æ¯ä¸ªé˜¶æ®µçš„è¿›åº¦å’Œç»“æœå¯é€šè¿‡å›è°ƒè·å–
    """

    def __init__(
        self,
        config_path: Path,
        max_concurrent_tasks: int = 3,
        enable_smart_merge: bool = True,
        progress_callback: Optional[Callable[[str, str, dict], None]] = None,
    ):
        """
        åˆå§‹åŒ–SimpleGraph

        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆconfig.yamlï¼‰
            max_concurrent_tasks: æœ€å¤§å¹¶å‘ä»»åŠ¡æ•°
            enable_smart_merge: æ˜¯å¦å¯ç”¨LLMæ™ºèƒ½åˆå¹¶
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•°ï¼Œç­¾åä¸º (task_id, step, progress_data) -> None
        """
        logger.info("=" * 60)
        logger.info("åˆå§‹åŒ– SimpleGraph")
        logger.info("=" * 60)

        self.config_path = config_path
        self.config = self._load_config()
        self.config_dir = config_path.parent
        self.max_concurrent_tasks = max_concurrent_tasks
        self.enable_smart_merge = enable_smart_merge

        # åˆå§‹åŒ– LLM å®¢æˆ·ç«¯
        logger.info("åˆå§‹åŒ– LLM å®¢æˆ·ç«¯...")
        model_config = self.config["models"]["default_chat_model"]
        api_key = self._get_api_key(model_config)
        verbose = model_config.get("verbose", False)

        self.llm_client = LLMClient(
            provider="ark",
            model="deepseek-v3-2-251201",
            base_url="https://ark.cn-beijing.volces.com/api/v3",
            verbose=verbose,
        )
        logger.info(f"LLM å®¢æˆ·ç«¯åˆå§‹åŒ–å®Œæˆ (verbose={verbose})")

        # åŠ è½½é¢„å®šä¹‰ System å’Œåˆ›å»º Graph
        logger.info("åŠ è½½é¢„å®šä¹‰ System...")
        self.system = System.from_config_file(self.config_path, use_base_system=True)
        logger.info(f"System åŠ è½½å®Œæˆ: {len(self.system.get_all_classes())} ä¸ªç±»")

        self.graph = Graph(system=self.system, include_predefined_entities=True)
        logger.info(
            f"Graph åˆ›å»ºå®Œæˆ: {self.graph.get_entity_count()} ä¸ªå®ä½“ï¼ˆå«é¢„å®šä¹‰ï¼‰"
        )

        # ä»»åŠ¡ç®¡ç†
        self.tasks: Dict[str, Task] = {}
        self.task_queue: asyncio.Queue = asyncio.Queue()  # ä»»åŠ¡é˜Ÿåˆ—ï¼ˆç”¨äºæå–é˜¶æ®µï¼‰
        self.merge_queue: asyncio.Queue = asyncio.Queue()  # åˆå¹¶é˜Ÿåˆ—ï¼ˆä¸²è¡Œæ‰§è¡Œï¼‰

        # åˆå§‹åŒ–æ™ºèƒ½åˆå¹¶å™¨
        smart_merge_prompt_path = self.config_dir / "prompts" / "smart_merge.txt"
        self.merger = SmartMerger(
            llm_client=self.llm_client,
            prompt_path=smart_merge_prompt_path,
            enable_smart_merge=enable_smart_merge,
        )
        logger.info(f"æ™ºèƒ½åˆå¹¶å™¨åˆå§‹åŒ–å®Œæˆ (enable_smart_merge={enable_smart_merge})")

        # åˆå§‹åŒ–ç®€å•åˆå¹¶å™¨ï¼ˆç”¨äºåº”ç”¨å¢é‡ï¼‰
        self.combiner = Combiner(self.graph, strict_validation=False)

        # åˆå§‹åŒ–æœç´¢å¼•æ“å¹¶å…³è”åˆ°Graph
        self.search_engine = self.graph._search_engine
        logger.info("æœç´¢å¼•æ“åˆå§‹åŒ–å®Œæˆ")

        # å¹¶å‘æ§åˆ¶
        self._worker_tasks: List[asyncio.Task] = []  # æå–ä»»åŠ¡çš„workers
        self._merge_worker_task: Optional[asyncio.Task] = None  # åˆå¹¶workerï¼ˆåªæœ‰1ä¸ªï¼‰
        self._running: bool = False

        # è¿›åº¦å›è°ƒ
        self._progress_callback = progress_callback

        logger.info("SimpleGraph åˆå§‹åŒ–å®Œæˆ")
        logger.info("=" * 60)

    def _load_config(self) -> dict:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        with open(self.config_path, "r", encoding="utf-8") as f:
            config = yaml.safe_load(f)
        return self._replace_env_vars(config)

    def _replace_env_vars(self, obj):
        """é€’å½’æ›¿æ¢ç¯å¢ƒå˜é‡"""
        if isinstance(obj, dict):
            return {k: self._replace_env_vars(v) for k, v in obj.items()}
        elif isinstance(obj, list):
            return [self._replace_env_vars(item) for item in obj]
        elif isinstance(obj, str) and obj.startswith("${") and obj.endswith("}"):
            env_var = obj[2:-1]
            return os.environ.get(env_var, obj)
        return obj

    def _get_api_key(self, model_config: dict) -> str:
        """è·å– API Key"""
        api_key = model_config.get("api_key")
        if api_key and api_key.startswith("${") and api_key.endswith("}"):
            api_key = os.environ.get(api_key[2:-1])
        elif not api_key:
            api_key = os.environ.get("MIMO_API_KEY")
        return api_key

    async def start(self):
        """å¯åŠ¨ä»»åŠ¡å¤„ç†å™¨"""
        if self._running:
            logger.warning("ä»»åŠ¡å¤„ç†å™¨å·²ç»åœ¨è¿è¡Œ")
            return

        logger.info(f"å¯åŠ¨ {self.max_concurrent_tasks} ä¸ªæå–workerså’Œ1ä¸ªåˆå¹¶worker...")
        self._running = True

        # å¯åŠ¨æå–workersï¼ˆå¯ä»¥å¹¶è¡Œï¼‰
        for i in range(self.max_concurrent_tasks):
            worker = asyncio.create_task(self._worker(worker_id=i))
            self._worker_tasks.append(worker)

        # å¯åŠ¨åˆå¹¶workerï¼ˆåªæœ‰1ä¸ªï¼Œä¸²è¡Œå¤„ç†ï¼‰
        self._merge_worker_task = asyncio.create_task(self._merge_worker())

        logger.info("ä»»åŠ¡å¤„ç†å™¨å¯åŠ¨å®Œæˆ")

    async def stop(self):
        """åœæ­¢ä»»åŠ¡å¤„ç†å™¨"""
        if not self._running:
            return

        logger.info("åœæ­¢ä»»åŠ¡å¤„ç†å™¨...")
        self._running = False

        # å–æ¶ˆæ‰€æœ‰æå–workers
        for worker in self._worker_tasks:
            worker.cancel()

        # å–æ¶ˆåˆå¹¶worker
        if self._merge_worker_task:
            self._merge_worker_task.cancel()

        # ç­‰å¾…æ‰€æœ‰workerç»“æŸ
        all_workers = self._worker_tasks + (
            [self._merge_worker_task] if self._merge_worker_task else []
        )
        await asyncio.gather(*all_workers, return_exceptions=True)

        self._worker_tasks.clear()
        self._merge_worker_task = None
        logger.info("ä»»åŠ¡å¤„ç†å™¨å·²åœæ­¢")

    async def submit_task(self, input_text: str) -> str:
        """
        æäº¤ä»»åŠ¡

        Args:
            input_text: è¾“å…¥çš„è‡ªç„¶è¯­è¨€æ–‡æœ¬

        Returns:
            ä»»åŠ¡ID
        """
        task_id = generate_task_id()

        # åˆ›å»ºsystemå‰¯æœ¬ï¼ˆä»»åŠ¡éš”ç¦»ï¼‰
        system_snapshot = self._create_system_snapshot()

        # åˆ›å»ºä»»åŠ¡
        task = Task(
            task_id=task_id,
            input_text=input_text,
            status="pending",
            system_snapshot=system_snapshot,
        )

        self.tasks[task_id] = task
        await self.task_queue.put(task)

        logger.info(f"ä»»åŠ¡å·²æäº¤: {task_id[:8]}...")
        logger.debug(f"ä»»åŠ¡å†…å®¹: {input_text[:100]}...")

        return task_id

    async def cancel_task(self, task_id: str) -> bool:
        """
        å–æ¶ˆä»»åŠ¡

        Args:
            task_id: ä»»åŠ¡ID

        Returns:
            æ˜¯å¦æˆåŠŸå–æ¶ˆ
        """
        task = self.tasks.get(task_id)
        if not task:
            logger.warning(f"ä»»åŠ¡ä¸å­˜åœ¨: {task_id}")
            return False

        if task.is_finished():
            logger.warning(f"ä»»åŠ¡å·²ç»“æŸï¼Œæ— æ³•å–æ¶ˆ: {task_id}")
            return False

        task.cancel()
        logger.info(f"ä»»åŠ¡å·²å–æ¶ˆ: {task_id[:8]}...")
        return True

    def get_task_status(self, task_id: str) -> Optional[dict]:
        """
        è·å–ä»»åŠ¡çŠ¶æ€

        Args:
            task_id: ä»»åŠ¡ID

        Returns:
            ä»»åŠ¡çŠ¶æ€å­—å…¸ï¼Œå¦‚æœä»»åŠ¡ä¸å­˜åœ¨è¿”å›None
        """
        task = self.tasks.get(task_id)
        if not task:
            return None

        return task.to_dict(include_snapshot=False)

    def get_all_tasks(self) -> List[dict]:
        """
        è·å–æ‰€æœ‰ä»»åŠ¡åˆ—è¡¨

        Returns:
            ä»»åŠ¡åˆ—è¡¨
        """
        return [task.to_dict(include_snapshot=False) for task in self.tasks.values()]

    def set_progress_callback(self, callback: Callable[[str, str, dict], None]):
        """
        è®¾ç½®è¿›åº¦å›è°ƒå‡½æ•°

        Args:
            callback: å›è°ƒå‡½æ•°ï¼Œç­¾åä¸º (task_id, step, progress_data) -> None
        """
        self._progress_callback = callback

    def get_task_progress(self, task_id: str) -> Optional[dict]:
        """
        è·å–ä»»åŠ¡çš„å½“å‰è¿›åº¦

        Args:
            task_id: ä»»åŠ¡ID

        Returns:
            è¿›åº¦ä¿¡æ¯å­—å…¸
        """
        task = self.tasks.get(task_id)
        if not task:
            return None
        return task.progress

    def get_task_stage_results(self, task_id: str) -> Optional[dict]:
        """
        è·å–ä»»åŠ¡çš„æ‰€æœ‰é˜¶æ®µç»“æœ

        Args:
            task_id: ä»»åŠ¡ID

        Returns:
            é˜¶æ®µç»“æœå­—å…¸
        """
        task = self.tasks.get(task_id)
        if not task:
            return None
        return task.get_all_stage_results()

    def get_statistics(self) -> dict:
        """
        è·å–ç»Ÿè®¡ä¿¡æ¯

        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        task_statuses = {}
        for status in ["pending", "running", "completed", "failed", "cancelled"]:
            task_statuses[status] = sum(
                1 for task in self.tasks.values() if task.status == status
            )

        return {
            "system": {
                "classes": len(self.system.get_all_classes()),
                "predefined_entities": len(self.system.predefined_entities),
            },
            "graph": {
                "entities": self.graph.get_entity_count(),
                "relationships": self.graph.get_relationship_count(),
            },
            "tasks": {
                "total": len(self.tasks),
                "by_status": task_statuses,
            },
        }

    def save(self, path: Path):
        """
        ä¿å­˜graphåˆ°æ–‡ä»¶

        Args:
            path: ä¿å­˜è·¯å¾„
        """
        logger.info(f"ä¿å­˜ Graph åˆ°: {path}")
        path.parent.mkdir(parents=True, exist_ok=True)
        self.graph.save(path)
        logger.info(f"Graph ä¿å­˜æˆåŠŸ: {path}")

    @classmethod
    def load(cls, config_path: Path, graph_path: Path, **kwargs) -> "SimpleGraph":
        """
        ä»æ–‡ä»¶åŠ è½½graphå¹¶åˆ›å»ºSimpleGraphå®ä¾‹

        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
            graph_path: graphæ–‡ä»¶è·¯å¾„
            **kwargs: å…¶ä»–åˆå§‹åŒ–å‚æ•°ï¼ˆmax_concurrent_tasks, enable_smart_mergeç­‰ï¼‰

        Returns:
            åŠ è½½çš„SimpleGraphå®ä¾‹
        """
        logger.info(f"ä»æ–‡ä»¶åŠ è½½ Graph: {graph_path}")

        if not graph_path.exists():
            raise FileNotFoundError(f"Graphæ–‡ä»¶ä¸å­˜åœ¨: {graph_path}")

        # åˆ›å»ºSimpleGraphå®ä¾‹ï¼ˆä¸åŒ…å«é¢„å®šä¹‰å®ä½“ï¼Œå› ä¸ºä¼šä»æ–‡ä»¶åŠ è½½ï¼‰
        instance = cls(config_path=config_path, **kwargs)

        # åŠ è½½graphï¼ˆä¼šè¦†ç›–é»˜è®¤åˆ›å»ºçš„ç©ºgraphï¼‰
        instance.graph = Graph.load(graph_path)

        # åŒæ­¥systemï¼ˆä»åŠ è½½çš„graphä¸­è·å–ï¼‰
        instance.system = instance.graph.system

        # é‡æ–°åˆå§‹åŒ– combinerï¼Œè®©å®ƒå¼•ç”¨æ–°åŠ è½½çš„ graph å®ä¾‹
        # è¿™æ˜¯å…³é”®ä¿®å¤ï¼šç¡®ä¿ combiner æ“ä½œçš„æ˜¯æ–°åŠ è½½çš„ graphï¼Œè€Œä¸æ˜¯åˆå§‹åŒ–æ—¶çš„ç©º graph
        from src.combiners.combiner import Combiner

        instance.combiner = Combiner(instance.graph, strict_validation=False)

        logger.info(
            f"Graph åŠ è½½æˆåŠŸ: {instance.graph.get_entity_count()} ä¸ªå®ä½“, "
            f"{instance.graph.get_relationship_count()} ä¸ªå…³ç³»"
        )

        return instance

    def visualize(self, output_path: Path, render_class_master_nodes: bool = True):
        """
        ç”Ÿæˆå¯è§†åŒ–

        Args:
            output_path: è¾“å‡ºè·¯å¾„
            render_class_master_nodes: æ˜¯å¦æ¸²æŸ“ç±»ä¸»èŠ‚ç‚¹
        """
        logger.info(f"ç”Ÿæˆå¯è§†åŒ–: {output_path}")
        output_path.parent.mkdir(parents=True, exist_ok=True)

        from graph_visualizer import GraphVisualizer

        visualizer = GraphVisualizer(title="Knowledge Graph")
        visualizer.from_simple_graphrag(
            self.graph, render_class_master_nodes=render_class_master_nodes
        )

    def _create_system_snapshot(self) -> System:
        """æ·±æ‹·è´å½“å‰systemä½œä¸ºå‰¯æœ¬"""
        return copy.deepcopy(self.system)

    def _notify_progress(self, task_id: str, step: str, data: dict):
        """
        é€šçŸ¥è¿›åº¦å›è°ƒ

        Args:
            task_id: ä»»åŠ¡ID
            step: å½“å‰æ­¥éª¤
            data: è¿›åº¦æ•°æ®
        """
        if self._progress_callback:
            try:
                self._progress_callback(task_id, step, data)
            except Exception as e:
                logger.error(f"è¿›åº¦å›è°ƒå¤±è´¥: {e}", exc_info=True)

    def _check_cancelled(self, task: Task):
        """æ£€æŸ¥ä»»åŠ¡æ˜¯å¦è¢«å–æ¶ˆ"""
        if task.is_cancelled():
            raise asyncio.CancelledError(f"ä»»åŠ¡ {task.task_id} è¢«å–æ¶ˆ")

    async def _run_task(self, task: Task) -> GraphDelta:
        """
        æ‰§è¡Œå•ä¸ªä»»åŠ¡ï¼Œè¿”å›å¢é‡æ›´æ–°åŒ…

        Args:
            task: ä»»åŠ¡å¯¹è±¡ï¼ˆåŒ…å«system_snapshotå’Œinput_textï¼‰

        Returns:
            GraphDeltaå¢é‡æ›´æ–°åŒ…

        Raises:
            asyncio.CancelledError: å¦‚æœä»»åŠ¡è¢«å–æ¶ˆ
        """
        logger.info(f"å¼€å§‹æ‰§è¡Œä»»åŠ¡: {task.task_id}")
        logger.debug(f"è¾“å…¥æ–‡æœ¬: {task.input_text[:100]}...")

        # ä½¿ç”¨ä»»åŠ¡çš„systemå‰¯æœ¬
        system = task.system_snapshot
        if system is None:
            raise ValueError("ä»»åŠ¡çš„system_snapshotä¸èƒ½ä¸ºNone")

        # åˆå§‹åŒ–å¢é‡æ•°æ®
        class_deltas: List[ClassDelta] = []
        entity_deltas: List[EntityDelta] = []
        relationship_deltas: List[RelationshipDelta] = []

        try:
            # æ£€æŸ¥å–æ¶ˆ
            self._check_cancelled(task)

            # Step 1: å¢é‡æ‰©å±• System
            step_msg = "æ­£åœ¨åˆ†ææ–‡æœ¬å¹¶æ›´æ–°Systemç±»å®šä¹‰..."
            task.update_progress("system_update", step_msg, 10)
            self._notify_progress(
                task.task_id, "system_update", {"message": step_msg, "percentage": 10}
            )

            logger.info(f"[ä»»åŠ¡ {task.task_id[:8]}] ğŸ”§ å¼€å§‹Systemæ›´æ–°é˜¶æ®µ")
            logger.info(
                f"[ä»»åŠ¡ {task.task_id[:8]}] è¾“å…¥æ–‡æœ¬: {task.input_text[:100]}..."
            )

            # è®°å½•è¾“å…¥æ•°æ®
            system_update_input = {
                "input_text": task.input_text,
                "existing_classes": system.get_all_classes(),
                "classes_count": len(system.get_all_classes()),
            }

            system, class_changes = await self._step_update_system(
                system, task.input_text
            )

            # è¯¦ç»†æ—¥å¿—è¾“å‡º
            if class_changes.get("needed"):
                logger.info(f"[ä»»åŠ¡ {task.task_id[:8]}] âœ… Systemæ›´æ–°å®Œæˆ:")
                for class_name in class_changes.get("added_classes", []):
                    class_def = system.get_class_definition(class_name)
                    if class_def:
                        logger.info(f"  âœ¨ æ–°å¢ç±»: {class_name}")
                        logger.info(f"     æè¿°: {class_def.description}")
                        props = [p.name for p in class_def.properties]
                        logger.info(
                            f"     å±æ€§: {', '.join(props) if props else '(æ— )'}"
                        )

                for class_name in class_changes.get("enhanced_classes", []):
                    class_def = system.get_class_definition(class_name)
                    if class_def:
                        logger.info(f"  ğŸ”§ å¢å¼ºç±»: {class_name}")
                        logger.info(f"     æè¿°: {class_def.description}")
                        props = [p.name for p in class_def.properties]
                        logger.info(
                            f"     å±æ€§: {', '.join(props) if props else '(æ— )'}"
                        )
            else:
                logger.info(
                    f"[ä»»åŠ¡ {task.task_id[:8]}] âœ“ Systemæ— éœ€æ›´æ–°ï¼Œç°æœ‰ç±»å®šä¹‰å·²è¶³å¤Ÿ"
                )

            # æ„å»ºè¯¦ç»†çš„ç±»ä¿¡æ¯
            added_classes_detail = []
            for class_name in class_changes.get("added_classes", []):
                class_def = system.get_class_definition(class_name)
                if class_def:
                    added_classes_detail.append(
                        {
                            "name": class_name,
                            "description": class_def.description,
                            "properties": [p.name for p in class_def.properties],
                        }
                    )

            enhanced_classes_detail = []
            for class_name in class_changes.get("enhanced_classes", []):
                class_def = system.get_class_definition(class_name)
                if class_def:
                    enhanced_classes_detail.append(
                        {
                            "name": class_name,
                            "description": class_def.description,
                            "properties": [p.name for p in class_def.properties],
                        }
                    )

            # è®°å½•è¾“å‡ºæ•°æ®
            system_update_output = {
                "needed": class_changes.get("needed", False),
                "added_classes": class_changes.get("added_classes", []),
                "enhanced_classes": class_changes.get("enhanced_classes", []),
                "added_classes_detail": added_classes_detail,
                "enhanced_classes_detail": enhanced_classes_detail,
                "total_classes_in_system": len(system.get_all_classes()),
                "llm_response_summary": class_changes.get("details", ""),
            }

            # ä¿å­˜é˜¶æ®µç»“æœï¼ˆåŒ…å«è¯¦ç»†çš„è¾“å…¥è¾“å‡ºå’ŒLLMå“åº”ï¼‰
            task.update_progress(
                "system_update",
                "Systemæ›´æ–°å®Œæˆ",
                30,
                result={
                    "needed": class_changes.get("needed", False),
                    "added_classes": class_changes.get("added_classes", []),
                    "enhanced_classes": class_changes.get("enhanced_classes", []),
                    "added_classes_detail": added_classes_detail,
                    "enhanced_classes_detail": enhanced_classes_detail,
                    "total_classes_in_system": len(system.get_all_classes()),
                    "details": class_changes.get("details", ""),
                },
                input_data=system_update_input,
                output_data=system_update_output,
                llm_response=class_changes.get("llm_raw_response"),
            )
            self._notify_progress(
                task.task_id,
                "system_update",
                {
                    "message": "Systemæ›´æ–°å®Œæˆ",
                    "percentage": 30,
                    "result": task.get_stage_result("system_update"),
                },
            )

            # è®°å½•ç±»çš„å˜æ›´
            for class_name in class_changes.get("added_classes", []):
                class_def = system.get_class_definition(class_name)
                if class_def:
                    class_deltas.append(
                        ClassDelta(
                            name=class_def.name,
                            description=class_def.description,
                            properties=[
                                PropertyDelta(
                                    name=prop.name,
                                    description=prop.description,
                                    required=prop.required,
                                    value_required=prop.value_required,
                                    operation="add",
                                )
                                for prop in class_def.properties
                            ],
                            operation="add",
                        )
                    )

            for class_name in class_changes.get("enhanced_classes", []):
                class_def = system.get_class_definition(class_name)
                if class_def:
                    class_deltas.append(
                        ClassDelta(
                            name=class_def.name,
                            description=class_def.description,
                            properties=[
                                PropertyDelta(
                                    name=prop.name,
                                    description=prop.description,
                                    required=prop.required,
                                    value_required=prop.value_required,
                                    operation="update",
                                )
                                for prop in class_def.properties
                            ],
                            operation="update",
                        )
                    )

            # æ£€æŸ¥å–æ¶ˆ
            self._check_cancelled(task)

            # Step 2: æå–å®ä½“å’Œå…³ç³»
            step_msg = "æ­£åœ¨ä»æ–‡æœ¬ä¸­æå–å®ä½“å’Œå…³ç³»..."
            task.update_progress("extraction", step_msg, 50)
            self._notify_progress(
                task.task_id, "extraction", {"message": step_msg, "percentage": 50}
            )

            logger.info(f"[ä»»åŠ¡ {task.task_id[:8]}] ğŸ” å¼€å§‹å®ä½“å’Œå…³ç³»æå–é˜¶æ®µ")

            # è®°å½•æå–é˜¶æ®µçš„è¾“å…¥
            extraction_input = {
                "input_text": task.input_text,
                "available_classes": system.get_all_classes(),
                "system_classes_count": len(system.get_all_classes()),
            }

            entities, relationships, extraction_llm_response = await self._step_extract(
                system, task.input_text
            )

            # è¯¦ç»†æ—¥å¿—è¾“å‡º
            logger.info(f"[ä»»åŠ¡ {task.task_id[:8]}] âœ… æå–å®Œæˆ:")
            logger.info(f"  ğŸ“¦ æå–åˆ° {len(entities)} ä¸ªå®ä½“:")
            for entity in entities:
                classes_str = ", ".join([c.class_name for c in entity.classes])
                logger.info(f"     â€¢ {entity.name} [{classes_str}]")
                logger.info(f"       æè¿°: {entity.description}")
                # æ˜¾ç¤ºå±æ€§
                for class_instance in entity.classes:
                    if class_instance.properties:
                        props_items = []
                        for k, v in class_instance.properties.items():
                            if v.value:
                                props_items.append(f"{k}={v.value}")
                        if props_items:
                            logger.info(f"       å±æ€§: {', '.join(props_items)}")

            logger.info(f"  ğŸ”— æå–åˆ° {len(relationships)} ä¸ªå…³ç³»:")
            for rel in relationships:
                count_str = f" (x{rel.count})" if rel.count > 1 else ""
                logger.info(f"     â€¢ {rel.source} â†’ {rel.target}{count_str}")
                logger.info(f"       {rel.description}")

            # æ„å»ºè¯¦ç»†çš„å®ä½“ä¿¡æ¯
            entities_detail = []
            for entity in entities:
                entity_info = {
                    "name": entity.name,
                    "description": entity.description,
                    "classes": [c.class_name for c in entity.classes],
                    "properties": {},
                }
                # æ”¶é›†æ‰€æœ‰ç±»çš„å±æ€§
                for class_instance in entity.classes:
                    if class_instance.properties:
                        entity_info["properties"][class_instance.class_name] = {
                            k: v.value for k, v in class_instance.properties.items()
                        }
                entities_detail.append(entity_info)

            # æ„å»ºè¯¦ç»†çš„å…³ç³»ä¿¡æ¯
            relationships_detail = []
            for rel in relationships:
                relationships_detail.append(
                    {
                        "source": rel.source,
                        "target": rel.target,
                        "description": rel.description,
                        "count": rel.count,
                    }
                )

            # è®°å½•æå–é˜¶æ®µçš„è¾“å‡º
            extraction_output = {
                "entities_count": len(entities),
                "relationships_count": len(relationships),
                "entities": entities_detail,
                "relationships": relationships_detail,
                "entity_names": [e.name for e in entities],
                "entity_classes": list(
                    set([c.class_name for e in entities for c in e.classes])
                ),
            }

            # ä¿å­˜é˜¶æ®µç»“æœï¼ˆåŒ…å«è¯¦ç»†çš„è¾“å…¥è¾“å‡ºå’ŒLLMå“åº”ï¼‰
            task.update_progress(
                "extraction",
                "æå–å®Œæˆ",
                80,
                result={
                    "entities_count": len(entities),
                    "relationships_count": len(relationships),
                    "entities": entities_detail,
                    "relationships": relationships_detail,
                    "entity_names": [e.name for e in entities],
                    "entity_classes": list(
                        set([c.class_name for e in entities for c in e.classes])
                    ),
                },
                input_data=extraction_input,
                output_data=extraction_output,
                llm_response=extraction_llm_response,
            )
            self._notify_progress(
                task.task_id,
                "extraction",
                {
                    "message": "æå–å®Œæˆ",
                    "percentage": 80,
                    "result": task.get_stage_result("extraction"),
                },
            )

            # è½¬æ¢ä¸ºå¢é‡æ ¼å¼
            for entity in entities:
                # æå–å®ä½“çš„å±æ€§å€¼
                properties_dict = {}
                for class_instance in entity.classes:
                    class_props = {}
                    for prop_name, prop_value in class_instance.properties.items():
                        class_props[prop_name] = prop_value.value or ""
                    if class_props:
                        properties_dict[class_instance.class_name] = class_props

                entity_deltas.append(
                    EntityDelta(
                        name=entity.name,
                        description=entity.description,
                        classes=[c.class_name for c in entity.classes],
                        properties=properties_dict,
                        operation="add",
                    )
                )

            for relationship in relationships:
                relationship_deltas.append(
                    RelationshipDelta(
                        source=relationship.source,
                        target=relationship.target,
                        description=relationship.description,
                        count=relationship.count,
                        refer=relationship.refer,  # ä¼ é€’ refer å­—æ®µ
                        operation="add",
                    )
                )

            # æ£€æŸ¥å–æ¶ˆ
            self._check_cancelled(task)

            # æ„å»ºGraphDelta
            delta = GraphDelta(
                task_id=task.task_id,
                classes=class_deltas,
                entities=entity_deltas,
                relationships=relationship_deltas,
                metadata={
                    "input_text": task.input_text[:200],
                    "entities_count": len(entity_deltas),
                    "relationships_count": len(relationship_deltas),
                    "classes_added": len(
                        [c for c in class_deltas if c.operation == "add"]
                    ),
                },
            )

            logger.info(f"ä»»åŠ¡æ‰§è¡Œå®Œæˆ: {delta.get_summary()}")
            return delta

        except asyncio.CancelledError:
            logger.info(f"ä»»åŠ¡è¢«å–æ¶ˆ: {task.task_id}")
            raise
        except Exception as e:
            logger.error(f"ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e}", exc_info=True)
            raise

    async def _worker(self, worker_id: int):
        """
        ä»»åŠ¡å·¥ä½œçº¿ç¨‹ï¼ˆå¼‚æ­¥ï¼‰

        Args:
            worker_id: Worker ID
        """
        logger.info(f"Worker {worker_id} å¯åŠ¨")

        while self._running:
            try:
                # ä»é˜Ÿåˆ—è·å–ä»»åŠ¡ï¼ˆå¸¦è¶…æ—¶ï¼‰
                try:
                    task = await asyncio.wait_for(self.task_queue.get(), timeout=1.0)
                except asyncio.TimeoutError:
                    continue

                logger.info(f"Worker {worker_id} å¼€å§‹å¤„ç†ä»»åŠ¡: {task.task_id[:8]}...")

                # æ ‡è®°ä»»åŠ¡å¼€å§‹
                task.start()
                self._notify_progress(
                    task.task_id, "started", {"message": "ä»»åŠ¡å·²å¼€å§‹", "percentage": 0}
                )

                try:
                    # æ‰§è¡Œä»»åŠ¡ï¼ˆæå–é˜¶æ®µï¼Œå¯å¹¶è¡Œï¼‰
                    delta = await self._run_task(task)

                    # æ ‡è®°ä»»åŠ¡å®Œæˆï¼ˆæå–é˜¶æ®µï¼‰
                    task.complete(delta)
                    self._notify_progress(
                        task.task_id,
                        "extraction_completed",
                        {
                            "message": "æå–é˜¶æ®µå®Œæˆï¼Œç­‰å¾…åˆå¹¶",
                            "percentage": 90,
                            "summary": delta.get_summary(),
                        },
                    )

                    # å°†ä»»åŠ¡æ”¾å…¥åˆå¹¶é˜Ÿåˆ—ï¼ˆä¸²è¡Œå¤„ç†ï¼‰
                    await self.merge_queue.put(task)

                    logger.info(
                        f"Worker {worker_id} æå–å®Œæˆï¼Œä»»åŠ¡è¿›å…¥åˆå¹¶é˜Ÿåˆ—: {task.task_id[:8]}..."
                    )

                except asyncio.CancelledError:
                    task.cancel()
                    self._notify_progress(
                        task.task_id, "cancelled", {"message": "ä»»åŠ¡å·²å–æ¶ˆ"}
                    )
                    logger.info(f"Worker {worker_id} ä»»åŠ¡è¢«å–æ¶ˆ: {task.task_id[:8]}...")

                except Exception as e:
                    task.fail(str(e))
                    self._notify_progress(
                        task.task_id, "failed", {"message": f"ä»»åŠ¡å¤±è´¥: {e}"}
                    )
                    logger.error(
                        f"Worker {worker_id} ä»»åŠ¡å¤±è´¥: {task.task_id[:8]}..., é”™è¯¯: {e}",
                        exc_info=True,
                    )

                finally:
                    self.task_queue.task_done()

            except asyncio.CancelledError:
                logger.info(f"Worker {worker_id} è¢«å–æ¶ˆ")
                break
            except Exception as e:
                logger.error(f"Worker {worker_id} å‘ç”Ÿæœªé¢„æœŸé”™è¯¯: {e}", exc_info=True)

        logger.info(f"Worker {worker_id} åœæ­¢")

    async def _merge_worker(self):
        """
        åˆå¹¶workerï¼ˆä¸²è¡Œå¤„ç†åˆå¹¶ä»»åŠ¡ï¼‰

        è¿™ä¸ªworkerä»merge_queueä¸­è·å–å·²å®Œæˆæå–çš„ä»»åŠ¡ï¼Œ
        é€ä¸ªè¿›è¡Œæ™ºèƒ½åˆå¹¶ï¼Œç¡®ä¿åˆå¹¶è¿‡ç¨‹ä¸²è¡Œæ‰§è¡Œï¼Œä¿è¯æ•°æ®ä¸€è‡´æ€§ã€‚
        """
        logger.info("Merge Worker å¯åŠ¨ï¼ˆä¸²è¡Œå¤„ç†ï¼‰")

        while self._running:
            try:
                # ä»åˆå¹¶é˜Ÿåˆ—è·å–ä»»åŠ¡ï¼ˆå¸¦è¶…æ—¶ï¼‰
                try:
                    task = await asyncio.wait_for(self.merge_queue.get(), timeout=1.0)
                except asyncio.TimeoutError:
                    continue

                logger.info(f"Merge Worker å¼€å§‹åˆå¹¶ä»»åŠ¡: {task.task_id[:8]}...")

                # é€šçŸ¥è¿›å…¥åˆå¹¶é˜¶æ®µ
                self._notify_progress(
                    task.task_id,
                    "merging",
                    {
                        "message": "å¼€å§‹æ™ºèƒ½åˆå¹¶åˆ°ä¸»å›¾è°±",
                        "percentage": 95,
                    },
                )

                try:
                    # æ‰§è¡Œåˆå¹¶ï¼ˆä¸²è¡Œï¼Œæ— éœ€åŠ é”ï¼‰
                    await self._auto_merge(task)

                    # åˆå¹¶æˆåŠŸï¼Œæ ‡è®°ä»»åŠ¡æœ€ç»ˆå®Œæˆ
                    self._notify_progress(
                        task.task_id,
                        "completed",
                        {
                            "message": "ä»»åŠ¡å·²å®Œæˆå¹¶åˆå¹¶",
                            "percentage": 100,
                        },
                    )

                    logger.info(f"Merge Worker ä»»åŠ¡åˆå¹¶å®Œæˆ: {task.task_id[:8]}...")

                except Exception as e:
                    # åˆå¹¶å¤±è´¥
                    task.fail(str(e))
                    self._notify_progress(
                        task.task_id,
                        "merge_failed",
                        {
                            "message": f"åˆå¹¶å¤±è´¥: {e}",
                            "percentage": 95,
                        },
                    )
                    logger.error(
                        f"Merge Worker ä»»åŠ¡åˆå¹¶å¤±è´¥: {task.task_id[:8]}..., é”™è¯¯: {e}",
                        exc_info=True,
                    )

                finally:
                    self.merge_queue.task_done()

            except asyncio.CancelledError:
                logger.info("Merge Worker è¢«å–æ¶ˆ")
                break
            except Exception as e:
                logger.error(f"Merge Worker å‘ç”Ÿæœªé¢„æœŸé”™è¯¯: {e}", exc_info=True)

        logger.info("Merge Worker åœæ­¢")

    async def _auto_merge(self, task: Task):
        """
        è‡ªåŠ¨åˆå¹¶ï¼ˆåœ¨merge_workerä¸­ä¸²è¡Œè°ƒç”¨ï¼Œæ— éœ€åŠ é”ï¼‰

        Args:
            task: å·²å®Œæˆçš„ä»»åŠ¡
        """
        if not task.result_delta or task.result_delta.is_empty():
            logger.info(f"ä»»åŠ¡ {task.task_id[:8]} å¢é‡ä¸ºç©ºï¼Œè·³è¿‡åˆå¹¶")
            return

        logger.info(f"å¼€å§‹æ™ºèƒ½åˆå¹¶ä»»åŠ¡ç»“æœ: {task.task_id[:8]}...")

        # è®°å½•åˆå¹¶é˜¶æ®µçš„è¾“å…¥æ•°æ®ï¼ˆè¯¦ç»†ï¼‰
        delta_dict = task.result_delta.to_dict()
        merge_input = {
            "delta_summary": task.result_delta.get_summary(),
            "enable_smart_merge": self.enable_smart_merge,
            "current_state": {
                "system_classes": len(self.system.get_all_classes()),
                "graph_entities": self.graph.get_entity_count(),
                "graph_relationships": self.graph.get_relationship_count(),
            },
            "delta_to_merge": {
                "classes": delta_dict.get("classes", []),
                "entities": delta_dict.get("entities", []),
                "relationships": delta_dict.get("relationships", []),
            },
            "statistics": {
                "classes_to_merge": len(delta_dict.get("classes", [])),
                "entities_to_merge": len(delta_dict.get("entities", [])),
                "relationships_to_merge": len(delta_dict.get("relationships", [])),
            },
        }

        try:
            # æ™ºèƒ½åˆå¹¶
            merge_result = await self.merger.merge_delta(
                self.system,
                self.graph,
                task.result_delta,
            )

            logger.info(f"æ™ºèƒ½åˆå¹¶å®Œæˆ: {merge_result.get_summary()}")

            # åº”ç”¨ä¼˜åŒ–åçš„å¢é‡åˆ°ä¸»system/graph
            stats = await self._apply_merge_result(merge_result.optimized_delta)

            logger.info(f"ä»»åŠ¡ç»“æœå·²åˆå¹¶åˆ°ä¸»å›¾è°±: {task.task_id[:8]}...")

            # è®°å½•åˆå¹¶é˜¶æ®µçš„è¾“å‡ºæ•°æ®ï¼ˆè¯¦ç»†ï¼‰
            optimized_dict = merge_result.optimized_delta.to_dict()
            merge_output = {
                "merge_summary": merge_result.get_summary(),
                "merge_statistics": {
                    "duplicates_found": merge_result.duplicates_found,
                    "conflicts_resolved": merge_result.conflicts_resolved,
                    "names_aligned": merge_result.names_aligned,
                    "descriptions_optimized": merge_result.descriptions_optimized,
                },
                "merge_notes": merge_result.notes,
                "apply_statistics": {
                    "entities_added": stats.get("entities", {}).get("added", 0),
                    "entities_updated": stats.get("entities", {}).get("updated", 0),
                    "relationships_added": stats.get("relationships", {}).get(
                        "added", 0
                    ),
                    "relationships_updated": stats.get("relationships", {}).get(
                        "updated", 0
                    ),
                },
                "final_state": {
                    "system_classes": len(self.system.get_all_classes()),
                    "graph_entities": self.graph.get_entity_count(),
                    "graph_relationships": self.graph.get_relationship_count(),
                },
                "optimized_delta": {
                    "classes": optimized_dict.get("classes", []),
                    "entities": optimized_dict.get("entities", []),
                    "relationships": optimized_dict.get("relationships", []),
                },
            }

            # ä¿å­˜åˆå¹¶é˜¶æ®µç»“æœï¼ˆåŒ…å«LLMè¾“å…¥è¾“å‡ºï¼‰
            task.update_progress(
                "merging",
                "åˆå¹¶å®Œæˆ",
                95,
                result={
                    "summary": merge_result.get_summary(),
                    "entities_added": stats.get("entities", {}).get("added", 0),
                    "entities_updated": stats.get("entities", {}).get("updated", 0),
                    "relationships_added": stats.get("relationships", {}).get(
                        "added", 0
                    ),
                    "relationships_updated": stats.get("relationships", {}).get(
                        "updated", 0
                    ),
                },
                input_data=merge_input,
                output_data=merge_output,
                llm_response=merge_result.llm_response,
            )

        except Exception as e:
            logger.error(f"åˆå¹¶å¤±è´¥: {e}", exc_info=True)
            raise

    async def _step_update_system(
        self, system: System, text: str
    ) -> tuple[System, Dict]:
        """
        æ­¥éª¤1: å¢é‡æ‰©å±• Systemï¼ˆå¼‚æ­¥ï¼‰

        Returns:
            (æ›´æ–°åçš„System, å˜æ›´ä¿¡æ¯)
        """
        logger.debug("æ­¥éª¤1: æ£€æŸ¥å¹¶å¢é‡æ‰©å±• System")

        # åˆå§‹åŒ– SystemUpdater
        updater = SystemUpdater(self.llm_client)

        # æ£€æŸ¥å¹¶æ›´æ–°
        system, changes = await self._check_and_update_async(updater, system, text)

        if changes["needed"]:
            logger.info(f"System å·²æ‰©å±•:")
            logger.info(f"  æ–°å¢ç±»: {changes['added_classes']}")
            logger.info(f"  å¢å¼ºç±»: {changes['enhanced_classes']}")
        else:
            logger.debug("System æ— éœ€æ‰©å±•")

        return system, changes

    async def _check_and_update_async(
        self, updater: SystemUpdater, system: System, text: str
    ) -> tuple[System, Dict]:
        """å¼‚æ­¥ç‰ˆæœ¬çš„check_and_update"""
        logger.debug("æ£€æŸ¥ System æ˜¯å¦éœ€è¦æ‰©å±•ï¼ˆå¼‚æ­¥ï¼‰")

        # ä¸€æ¬¡æ€§å®Œæˆæ£€æŸ¥å’Œé…ç½®ç”Ÿæˆï¼ˆè¿”å›3ä¸ªå€¼ï¼‰
        need_update, incremental_config, llm_response = (
            await self._check_and_generate_async(updater, system, text)
        )

        if not need_update:
            logger.debug("ç°æœ‰ System è¶³å¤Ÿï¼Œæ— éœ€æ‰©å±•")
            return system, {
                "needed": False,
                "added_classes": [],
                "enhanced_classes": [],
                "details": "ç°æœ‰ç³»ç»Ÿè¶³å¤Ÿ",
                "llm_raw_response": llm_response,
            }

        if not incremental_config or "classes" not in incremental_config:
            logger.warning("LLM æœªè¿”å›æœ‰æ•ˆçš„å¢é‡é…ç½®")
            return system, {
                "needed": True,
                "added_classes": [],
                "enhanced_classes": [],
                "details": "LLM æœªè¿”å›æœ‰æ•ˆé…ç½®",
            }

        logger.info(f"éœ€è¦æ‰©å±• Systemï¼Œæ¶‰åŠ {len(incremental_config['classes'])} ä¸ªç±»")

        # åº”ç”¨æ›´æ–°
        added, enhanced = updater._apply_update(system, incremental_config)
        logger.info(
            f"System æ‰©å±•å®Œæˆ: æ–°å¢ {len(added)} ä¸ªç±», å¢å¼º {len(enhanced)} ä¸ªç±»"
        )

        return system, {
            "needed": True,
            "added_classes": added,
            "enhanced_classes": enhanced,
            "details": f"æ–°å¢ {len(added)} ä¸ªç±», å¢å¼º {len(enhanced)} ä¸ªç±»",
        }

    async def _check_and_generate_async(
        self, updater: SystemUpdater, system: System, text: str
    ) -> tuple[bool, Dict, str]:
        """å¼‚æ­¥ç‰ˆæœ¬çš„_check_and_generateï¼Œè¿”å› (need_update, config, llm_response)"""
        system_yaml = yaml.dump(
            {
                "classes": {
                    name: system.get_class_definition(name).to_dict()
                    for name in system.get_all_classes()
                }
            },
            allow_unicode=True,
            default_flow_style=False,
        )

        logger.debug("è°ƒç”¨ LLM æ£€æŸ¥å¹¶ç”Ÿæˆé…ç½®ï¼ˆå¼‚æ­¥ï¼‰...")
        response = await self.llm_client.extract_text_async(
            prompt_template=updater.prompt_template,
            temperature=0.3,
            system_yaml=system_yaml,
            text=text,
        )

        logger.debug(f"LLM å“åº”é•¿åº¦: {len(response)} å­—ç¬¦")

        # è§£æå“åº”
        if "SUFFICIENT" in response.upper():
            logger.debug("LLM åˆ¤æ–­ï¼šç³»ç»Ÿè¶³å¤Ÿ")
            return False, {}, response

        # å°è¯•è§£æä¸º YAML é…ç½®
        try:
            config = updater._parse_yaml_response(response)
            if config and "classes" in config and config["classes"]:
                logger.debug(f"è§£æåˆ°å¢é‡é…ç½®: {list(config['classes'].keys())}")
                return True, config, response
            else:
                logger.warning("LLM å“åº”ä¸åŒ…å«æœ‰æ•ˆçš„ç±»å®šä¹‰")
                return False, {}, response
        except Exception as e:
            logger.error(f"è§£æ LLM å“åº”å¤±è´¥: {e}")
            return False, {}, response

    async def _step_extract(
        self, system: System, text: str
    ) -> tuple[List[Entity], List, str]:
        """
        æ­¥éª¤2: æå–å®ä½“å’Œå…³ç³»ï¼ˆå¼‚æ­¥ï¼‰

        Returns:
            (å®ä½“åˆ—è¡¨, å…³ç³»åˆ—è¡¨, LLMå“åº”)
        """
        logger.debug("æ­¥éª¤2: æå–å®ä½“å’Œå…³ç³»")

        # åˆå§‹åŒ– GraphExtractor
        extraction_config = self.config.get("extraction", {})
        prompts_config = self.config["prompts"]
        extract_prompt_path = self.config_dir / prompts_config["extract_graph"]

        # å‡†å¤‡åŸºç¡€å®ä½“ä¿¡æ¯
        base_entities = [
            {
                "name": e.name,
                "description": e.description,
                "classes": e.classes,
            }
            for e in system.predefined_entities
        ]

        extractor = GraphExtractor(
            llm_client=self.llm_client,
            prompt_template_path=extract_prompt_path,
            classes=system.get_all_classes(),
            system=system,
            tuple_delimiter=extraction_config.get("tuple_delimiter", "|"),
            record_delimiter=extraction_config.get("record_delimiter", "^"),
            completion_delimiter=extraction_config.get("completion_delimiter", "DONE"),
            language=extraction_config.get("language", "ä¸­æ–‡"),
            base_entities=base_entities,
            enable_check=extraction_config.get("enable_check", True),
        )

        # å¼‚æ­¥æå–
        entities, relationships, llm_response = await self._extract_async(
            extractor, text
        )

        logger.info(f"æå–å®Œæˆ: {len(entities)} ä¸ªå®ä½“, {len(relationships)} ä¸ªå…³ç³»")

        return entities, relationships, llm_response

    async def _extract_async(self, extractor: GraphExtractor, text: str):
        """å¼‚æ­¥ç‰ˆæœ¬çš„extractï¼Œè¿”å› (entities, relationships, llm_response)"""
        logger.debug("å¼€å§‹å¼‚æ­¥ä¸‰æ­¥æå–ï¼šå®ä½“ -> ç±»å±æ€§ -> å…³ç³»")

        # å‡†å¤‡æ¨¡æ¿å˜é‡
        classes_str = ",".join(extractor.classes)
        classes_info = extractor._generate_classes_info()
        base_entities_info = extractor._format_base_entities()

        # è°ƒç”¨LLMæå–ï¼ˆå¼‚æ­¥ï¼‰
        logger.debug("è°ƒç”¨LLMè¿›è¡Œä¸‰æ­¥æå–ï¼ˆå¼‚æ­¥ï¼‰...")
        response = await self.llm_client.extract_text_async(
            prompt_template=extractor.prompt_template,
            input_text=text,
            entity_types=classes_str,
            tuple_delimiter=extractor.tuple_delimiter,
            record_delimiter=extractor.record_delimiter,
            completion_delimiter=extractor.completion_delimiter,
            language=extractor.language,
            classes_info=classes_info,
            base_entities_info=base_entities_info,
        )

        logger.debug(f"LLMå“åº”é•¿åº¦: {len(response)} å­—ç¬¦")

        # å¦‚æœå¯ç”¨æ£€æŸ¥ï¼Œè¿›è¡ŒäºŒæ¬¡ä¼˜åŒ–ï¼ˆå¼‚æ­¥ï¼‰
        if extractor.enable_check:
            logger.info("å¼€å§‹æ£€æŸ¥å’Œä¼˜åŒ–æå–ç»“æœï¼ˆå¼‚æ­¥ï¼‰...")
            checked_response = await self._check_extraction_async(
                extractor, text, response, classes_str
            )
            response = checked_response
            logger.info("æ£€æŸ¥ä¼˜åŒ–å®Œæˆ")

        # è§£æå“åº”
        entities, relationships = extractor._parse_response(response)

        return entities, relationships, response

    async def _check_extraction_async(
        self,
        extractor: GraphExtractor,
        input_text: str,
        extraction_result: str,
        entity_types: str,
    ) -> str:
        """å¼‚æ­¥ç‰ˆæœ¬çš„_check_extraction"""
        logger.debug("è°ƒç”¨æ£€æŸ¥LLMä¼˜åŒ–æå–ç»“æœï¼ˆå¼‚æ­¥ï¼‰...")

        response = await self.llm_client.extract_text_async(
            prompt_template=extractor.check_template,
            temperature=0.3,
            input_text=input_text,
            extraction_result=extraction_result,
            entity_types=entity_types,
        )

        return response

    async def _apply_merge_result(self, optimized_delta: GraphDelta):
        """
        åº”ç”¨ä¼˜åŒ–åçš„å¢é‡åˆ°ä¸»system/graph

        Args:
            optimized_delta: ä¼˜åŒ–åçš„å¢é‡æ›´æ–°åŒ…

        Returns:
            åˆå¹¶ç»Ÿè®¡ä¿¡æ¯
        """
        logger.debug("åº”ç”¨å¢é‡æ›´æ–°åˆ°ä¸»system/graph...")

        # åº”ç”¨ç±»å¢é‡åˆ°system
        for class_delta in optimized_delta.classes:
            properties = [
                PropertyDefinition(
                    name=prop.name,
                    description=prop.description,
                    required=prop.required if prop.required is not None else False,
                    value_required=(
                        prop.value_required
                        if prop.value_required is not None
                        else False
                    ),
                )
                for prop in class_delta.properties
            ]

            class_def = ClassDefinition(
                name=class_delta.name,
                description=class_delta.description,
                properties=properties,
            )

            self.system.add_class_definition(class_def)

        # åº”ç”¨å®ä½“å’Œå…³ç³»å¢é‡åˆ°graph
        # è½¬æ¢å¢é‡ä¸ºEntityå’ŒRelationshipå¯¹è±¡
        entities = []
        for entity_delta in optimized_delta.entities:
            entity = Entity(
                name=entity_delta.name,
                description=entity_delta.description or "",
            )

            # æ·»åŠ ç±»å’Œå±æ€§
            for class_name in entity_delta.classes:
                class_instance = entity.add_class(class_name, system=self.system)

                # è®¾ç½®å±æ€§å€¼
                class_props = entity_delta.properties.get(class_name, {})
                for prop_name, prop_value in class_props.items():
                    try:
                        entity.set_property_value(
                            class_name, prop_name, value=prop_value, system=self.system
                        )
                    except Exception as e:
                        logger.warning(f"è®¾ç½®å±æ€§å¤±è´¥: {e}")

            entities.append(entity)

        relationships = []
        increment_count_stats = {"incremented": 0, "not_found": 0}

        for rel_delta in optimized_delta.relationships:
            if rel_delta.operation == "increment_count":
                # å¤„ç†increment_countæ“ä½œï¼šæŸ¥æ‰¾å¹¶å¢åŠ ç°æœ‰å…³ç³»çš„count
                increment_amount = rel_delta.increment_amount
                if increment_amount <= 0:
                    logger.warning(
                        f"increment_countæ“ä½œçš„increment_amountæ— æ•ˆ: {increment_amount}, "
                        f"å…³ç³»: {rel_delta.source} -> {rel_delta.target}"
                    )
                    continue

                # æŸ¥æ‰¾åŒ¹é…çš„ç°æœ‰å…³ç³»ï¼ˆsourceã€targetã€descriptionã€referéƒ½ç›¸åŒï¼‰
                found = False
                for existing_rel in self.graph.get_relationships():
                    # ä½¿ç”¨å¤§å°å†™ä¸æ•æ„Ÿæ¯”è¾ƒ
                    source_match = (
                        existing_rel.source.upper() == rel_delta.source.upper()
                    )
                    target_match = (
                        existing_rel.target.upper() == rel_delta.target.upper()
                    )
                    desc_match = existing_rel.description == rel_delta.description
                    # referæ•°ç»„æ¯”è¾ƒï¼ˆé¡ºåºæ— å…³ï¼Œå¤§å°å†™ä¸æ•æ„Ÿï¼‰
                    refer_set_existing = set([r.upper() for r in existing_rel.refer])
                    refer_set_delta = set([r.upper() for r in rel_delta.refer])
                    refer_match = refer_set_existing == refer_set_delta

                    if source_match and target_match and desc_match and refer_match:
                        # æ‰¾åˆ°åŒ¹é…çš„å…³ç³»ï¼Œå¢åŠ å…¶count
                        old_count = existing_rel.count
                        existing_rel.count += increment_amount

                        # è¿½åŠ è¯­ä¹‰æ—¶é—´åˆ°ç°æœ‰å…³ç³»
                        if rel_delta.semantic_times:
                            existing_rel.semantic_times.extend(rel_delta.semantic_times)
                            logger.info(
                                f"increment_count: {rel_delta.source} -> {rel_delta.target}, "
                                f"countä» {old_count} å¢åŠ åˆ° {existing_rel.count} (+{increment_amount}), "
                                f"è¿½åŠ  {len(rel_delta.semantic_times)} ä¸ªè¯­ä¹‰æ—¶é—´"
                            )
                        else:
                            logger.info(
                                f"increment_count: {rel_delta.source} -> {rel_delta.target}, "
                                f"countä» {old_count} å¢åŠ åˆ° {existing_rel.count} (+{increment_amount})"
                            )

                        found = True
                        increment_count_stats["incremented"] += 1
                        break

                if not found:
                    logger.warning(
                        f"increment_countæ“ä½œæœªæ‰¾åˆ°åŒ¹é…çš„ç°æœ‰å…³ç³»: "
                        f"{rel_delta.source} -> {rel_delta.target} "
                        f"(description={rel_delta.description}, refer={rel_delta.refer}), "
                        f"å°†ä½œä¸ºæ–°å…³ç³»æ·»åŠ "
                    )
                    # æœªæ‰¾åˆ°åŒ¹é…å…³ç³»ï¼Œä½œä¸ºæ–°å…³ç³»æ·»åŠ 
                    relationship = Relationship(
                        source=rel_delta.source,
                        target=rel_delta.target,
                        description=rel_delta.description,
                        count=increment_amount,  # ä½¿ç”¨increment_amountä½œä¸ºåˆå§‹count
                        refer=rel_delta.refer,
                        semantic_times=rel_delta.semantic_times,  # ä¼ é€’ semantic_times å­—æ®µ
                    )
                    relationships.append(relationship)
                    increment_count_stats["not_found"] += 1
            else:
                # å…¶ä»–æ“ä½œï¼šæ­£å¸¸æ·»åŠ å…³ç³»
                relationship = Relationship(
                    source=rel_delta.source,
                    target=rel_delta.target,
                    description=rel_delta.description,
                    count=rel_delta.count,
                    refer=rel_delta.refer,  # ä¼ é€’ refer å­—æ®µ
                    semantic_times=rel_delta.semantic_times,  # ä¼ é€’ semantic_times å­—æ®µ
                )
                relationships.append(relationship)

        # ä½¿ç”¨Combineråˆå¹¶åˆ°graph
        stats = self.combiner.combine(entities, relationships)

        # æ·»åŠ increment_countç»Ÿè®¡
        if (
            increment_count_stats["incremented"] > 0
            or increment_count_stats["not_found"] > 0
        ):
            logger.info(
                f"increment_countæ“ä½œç»Ÿè®¡: æˆåŠŸå¢åŠ  {increment_count_stats['incremented']} ä¸ª, "
                f"æœªæ‰¾åˆ°åŒ¹é… {increment_count_stats['not_found']} ä¸ª"
            )

        logger.info(
            f"åº”ç”¨å¢é‡å®Œæˆ: å®ä½“ +{stats['entities']['added']}/~{stats['entities']['updated']}, "
            f"å…³ç³» +{stats['relationships']['added']}/~{stats['relationships']['updated']}"
        )

        return stats

    # ==================== æœç´¢åŠŸèƒ½ ====================

    def search_keyword(
        self, keyword: str, fuzzy: bool = True, limit: Optional[int] = None
    ):
        """
        å…³é”®è¯æœç´¢

        Args:
            keyword: æœç´¢å…³é”®è¯
            fuzzy: æ˜¯å¦æ¨¡ç³Šæœç´¢
            limit: ç»“æœæ•°é‡é™åˆ¶

        Returns:
            æœç´¢ç»“æœåˆ—è¡¨
        """
        return self.search_engine.search_keyword(keyword, fuzzy, limit)

    def get_node_detail(self, node_id: str):
        """
        è·å–èŠ‚ç‚¹è¯¦æƒ…

        Args:
            node_id: èŠ‚ç‚¹IDï¼ˆå¯ä»¥æ˜¯å®ä½“åã€ç±»èŠ‚ç‚¹IDç­‰ï¼‰

        Returns:
            èŠ‚ç‚¹è¯¦æƒ…å¯¹è±¡
        """
        return self.search_engine.get_node_detail(node_id)

    def get_entity_node_group(self, entity_name: str):
        """
        è·å–å®ä½“èŠ‚ç‚¹ç»„ï¼ˆå®ä½“+æ‰€æœ‰ç±»èŠ‚ç‚¹+ä¸€å±‚å…³ç³»ï¼‰

        Args:
            entity_name: å®ä½“åç§°

        Returns:
            å®ä½“èŠ‚ç‚¹ç»„å¯¹è±¡
        """
        return self.search_engine.get_entity_node_group(entity_name)

    def get_class_node_group(self, class_name: str):
        """
        è·å–ç±»èŠ‚ç‚¹ç»„ï¼ˆæ‰€æœ‰è¯¥ç±»çš„å®ä½“ç±»èŠ‚ç‚¹ï¼‰

        Args:
            class_name: ç±»åç§°

        Returns:
            ç±»èŠ‚ç‚¹ç»„å¯¹è±¡
        """
        return self.search_engine.get_class_node_group(class_name)
